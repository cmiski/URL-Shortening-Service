initialize project
  npm init -y

do "dev" : "node --watch " for nodemon watching

install dependencies
  npm install express dotenv zod pino
  npm install ioredis kafkajs mongoose

docker-compose.yml is a config file for docker compose to define and run multi container docker applications (kinda like a blueprint that tells docker how to build and run the application)
  every container(service) can talk to each other uisng service name

  "docker compose up -d" --> starts all containers
  "docker compose ps" --> displays all running containers
  "docker composr logs" --> displays all logs
  "docker compose down": stops all containers, but leaves volumes intact
  "docker compose down -v": stops all containers and removes all volumes

  "docker exec -it <container name> redis-cli" --> to access redis cli
  "docker exec -it <container name> redis-cli ping" --> to check if redis is running
  "docker exec -it <container name> rpk cluster info" --> to check if redpanda is running

  my yml file is a optimezed setup for backend systems, event-driven architecture, Caching + DB + Streaming, microservices etc
    refer docker-compose.yml for details

  PHASE 1: CORE REDIRECT ENGINE (performance critical)
    --> this defines the latency discipline for the entire project

    --? Note : "The redirect path must be boring, fast, and dumb."

      ^^ created basic foundational express server [src/app.js, src/server.js]
      ^^ created health check endpoint [src/routes/health.js]
      ^^ configured DB connection [src/config/db.js]
      ^^ configured Redis connection [src/config/redis.js]
      ^^ created URL model [src/models/url.model.js]

    "index : true" in the DB URL schema means that the field will be indexed for faster lookup O(log n) instead of O(n) --> Mongo creates a B-tree index internally 


  CACHE-ASIDE STRATEGY/PATTERN : 
      1) cache hit : read data from cache if available
      2) cache miss : read data from DB
      3) wtite data to cache

    Note: for read only paths always use lean()

      ^^ created redirect service : resolveShortCode -> finds the long url and returns it to the redirect controller [src/services/redirect.service.js]
      ^^ created redirect controller : redirectHandler -> if long Url found redirect to that url and send 302 [src/controllers/redirect.controller.js]
      ^^ created redirect route : /:shortcut [src/routes/redirect.js]


    Note: never run plain mongosh for docker db, use "docker exec -it urlshorteningservice-mongo-1 mongosh"


    My redirect is working now (it redirects to gws i.e goole web server) so it hides the 302 and just show 200 on the redirected url

      current flow : 
        Client
           ──▶ My server (302 Redirect)
                 ──▶ https://google.com
                       ──▶ Google responds with 200 OK + HTML


        So rn, i have a high-performance redirect path with redis-first cache-aside strategy.


URL CREATION API -> WRITE PATH ENGINEERING

  POST /api/shorten -> accepts a long URL, return a shortcode and is idempotent(API behavior -> what the client sees) meaning that if the same long url is sent again, it will return the same shortcode, is also collision safe(ty is about what the database guarantees) meaning no two urls can have the same shortcode (base62 + counter is always collision free), warms redis(optimise future reads) and emits Kafka events(async non blocking)
                    
    Architecture : POST /api/shorten --> validate input --> check DB(idempotency) --> Generate shortcode --> Insert (on collisions -> retry) --> write-through Cache in Redis --> Emit kafka event (async, fire and forget) -> return response


  Note: for data-cacheing i am using both 
    
    1) Cache-Aside i.e lazy cacheing on read(redirect)
      --> redis is populated only after a read happen
      --> this is good but it causes cold cache problem i.e. the first redirect is slower cuz it hits the DB then only it goes into redis after the first read
      --> also bad cuz of Thundering Herd problem -> imagine 10000 req -> redis miss(cold cache) -> DB spikes -> latency fucked -> outage
    
    2) Write-through i.e 'eager cacheing' on write/create ----> warming the cache at creation
      --> redis is populated on write i.e. when data is written to the DB, it is also written to Redis immediately, so even the first redirect is fast and not expensive cuz it is cache HIT
      --> zero DB hits on the first redirect

  Note: write on HOT paths are dangerous --> Slow path (create) does extra work to make HOT path(redirect) fast

    ^^ created generateBase62() to generate a random base62 string of a given length [src/utils/base62.js]

    request -> 
              {
                "longUrl": "https://google.com",
              }
    response -> 
                {
                  "shortCode": "aZ3X91q"
                  "shortUrl": "https://localhost:3000/aZ3X91q"
                }

    Note: DB based idempotency check because redis is volatile and DB is authoritative

        race-safe : means my code behaves correctly even when multiple requests run at the same time simultaneously
            --> my code is atomicly race-safe proof -> shortcode model is unique therefore no two documents can share the same shortcode
            --> Race-safe code lets the database decide, and handles failure — not the other way around.
            --> even if two requests generate the same shortcode, mongodb reject the second request and generates a new shortcode for it and handeling errors gracefully

    ^^ created shortenUrlHandler() to handle the POST /api/shorten request [src/controllers/shorten.controller.js]
    ^^ created /shorten route [src/routes/shorten.js]
    ^^ created /api -> shortenUrl [src/app.js]


        This all ensures Idempotency : same URL -> same shortcode : avoids DB bloat
          & collision retry loop : handle collisions deterministically
          & race-safe : handle multiple requests at the same time
          & redis warm up : first redirect is already cached


  INPUT VALIDATION AND URL NORMALIZATION
    ill reject invalid input/requests early  using ZOD
    & normalize URLs at the boundry so idempotency is actually correct -> google.com , http://google.com , https://google.com , www.google.com all are the same thing


    ^^created shorten.schema.js to validate input using zod [src/validation/shorten.schema.js]
        --> if any of this fails -> No DB call, No redis, No kafka, No wasted CPU

    ^^ created normalizeUrl() to normalize URLs (read file for details) [src/utils/normalizeUrl.js]
    ^^ updated shortenUrlHandler() to validate req body using zod safeParse() and use normalizeUrl() [src/controllers/shorten.controller.js]


  as zod was validating before normalizing(before was in the controller) it wasnt treating "google.com" as a valid URL 
      so i had to add normalization in zod schema and remove normalization from the controller

      now that is fixed but i found a new bug if i send any "not-a-valid-url" it  makes it a valid url format and generates a shortURL for it.

        This should never be accepted by a production URL shortener
          Note: Normalization must NEVER make an invalid URL valid


        z/string().url() --> only checks url syntax, scheme exists but not check the DNS validity
        hostname must contain a dot 
        validation must happen before normalization


        ^^ created isValidHostname() to check if a hostname is valid [src/utils/isValidHostname.js]
        ^^ fixed validation --> no normalization here only validate [src/validation/shorten.schema.js]
        ^^ updated shortenUrlHandler() again to  use normalizeUrl() [src/controllers/shorten.controller.js]


        ^^ updated zod schema (see file for details) [src/validation/shorten.schema.js]

        NOTE: "Be nice to users (accept urls without protocol), but be strict about security (only http/https + valid public-looking hostnames)"


  "docker exec -it urlshorteningservice-redis-1 redis-cli MONITOR" --> to monitor redis


# Idempotency is not being enforced at DB level -> i dont store a canonical URL field 00> db has no way to enforce 'same URL only once'


Note: Different representations → same canonical URL → same shortCode


idempotency + race-condition shield in my db : {
    v: 2,
    key: { normalizedUrl: 1 },
    name: 'normalizedUrl_1',
    unique: true
  }


Redis-Backed Idempotency --> Hot Path Optimization --> make it fast

    for POST /api/shorten : check redis first -> if found : return immediately (0 DB calls/hits) -> if not found : hit DB and write to redis

  shorten.service structure -> normalize --> redis.get -->if hit, return --> try create : catch duplicate :find --> redis.set -->return


  for url validation i am also checking DNS validity 


  was having a redirect bug where it was redirecting to longUrl which was not normalised so created a new field in DB called rawLongUrl abd made longeUrl:normalizedUrl


  system status as of rn:
    Normalization is done before persistence
    DB-lvl uniqueness on normalizedUrl
    idempotent POST /api/shorten
    correct redirection on GET /:shortCode

    Redis hot path for /api/shorten and /:shortCode
    DB hits avoided for repeated requests

    Source of truth is DB
    Cahche : Redis
    Race safe creation
    explicit user inputed raw vs canonical data sepration
